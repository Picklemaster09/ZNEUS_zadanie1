{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7795,
     "status": "ok",
     "timestamp": 1762287149328,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "CeKLV9k6aJbA",
    "outputId": "37352aed-1a5d-4c45-a37d-d1a6dbfb5d0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 18387,
     "status": "ok",
     "timestamp": 1762287167722,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "J2ueneUrVirD",
    "outputId": "2a05722b-17cc-422b-98d1-cbe4b36c966e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "seed = 50\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "csv_path = \"https://raw.githubusercontent.com/marekfejda/ZNEUS_data/refs/heads/main/phpSSK7iA.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 35368,
     "status": "ok",
     "timestamp": 1762287203102,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "jAI6PxcCWyB9",
    "outputId": "eaacfbf5-b60a-4d68-ddb2-602083685ca7"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "print(\"\\nColumns with missing values or unexpected types\")\n",
    "\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "non_float_cols = [col for col in df.columns if df[col].dtype != float]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"\\n--- Columns with missing values ---\")\n",
    "    for col in missing_cols:\n",
    "        print(col, df[col].isnull().sum())\n",
    "else:\n",
    "    print(\"No missing-value columns found.\")\n",
    "\n",
    "if len(non_float_cols) > 0:\n",
    "    print(\"\\n--- Columns with unexpected types ---\")\n",
    "    for col in non_float_cols:\n",
    "        print(col, df[col].dtype)\n",
    "else:\n",
    "    print(\"No non-float columns found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = df['target'].unique()\n",
    "print(\"Unique values for target:\", unique_vals)\n",
    "\n",
    "# Count how many 0s and 1s\n",
    "value_counts = df['target'].value_counts()\n",
    "print(\"\\nCounts per value:\")\n",
    "for val, count in value_counts.items():\n",
    "    print(f\"  {val}: {count}\")\n",
    "\n",
    "# show class balance ratio\n",
    "ratio = value_counts / len(df)\n",
    "print(\"\\nProportion per value:\")\n",
    "for val, r in ratio.items():\n",
    "    print(f\"  {val}: {r:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"min\": df.min(numeric_only=True),\n",
    "    \"max\": df.max(numeric_only=True)\n",
    "})\n",
    "\n",
    "summary = summary.reset_index().rename(columns={'index': 'feature'})\n",
    "# The graphs were created with the assistance of AI tools\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(summary[\"feature\"], summary[\"min\"], label=\"Min\", alpha=0.7)\n",
    "plt.plot(summary[\"feature\"], summary[\"max\"], label=\"Max\", alpha=0.7)\n",
    "plt.title(\"Min and Max Values per Numeric Column\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.xticks([], [])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected three different methods for feature selection, merged their results into a unified ranking, and then chose the final features based on that combined selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation feature selection\n",
    "\n",
    "The graphs were created with the assistance of AI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corrwith(y)\n",
    "\n",
    "corr_abs = corr.abs().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(corr_abs)), corr_abs, color='steelblue', alpha=0.8)\n",
    "plt.title('Absolute Correlation of Each Feature with Target', fontsize=14)\n",
    "plt.xlabel('Feature Index (sorted by correlation strength)')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# correlation distribution\n",
    "plt.hist(corr_abs, bins=50, color='orange', alpha=0.7)\n",
    "plt.title('Distribution of Feature Correlations with Target')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(corr.abs())), corr.abs(), color='steelblue', alpha=0.8)\n",
    "plt.title('Absolute Correlation of Each Feature with Target', fontsize=14)\n",
    "plt.xlabel('Feature Index (original order)')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mutual information\n",
    "\n",
    "The graphs were created with the assistance of AI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X, y, random_state=seed)\n",
    "    \n",
    "scores = pd.Series(mi, index=X.columns)\n",
    "scores_sorted = scores.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(scores_sorted)), scores_sorted.values, color='steelblue', alpha=0.8)\n",
    "plt.title('Mutual Information Feature Scores', fontsize=14)\n",
    "plt.xlabel('Feature Index (sorted by MI score)')\n",
    "plt.ylabel('Mutual Information')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# correlation distribution\n",
    "plt.hist(scores.values, bins=50, color='orange', alpha=0.7)\n",
    "plt.title('Distribution of Mutual Information Scores', fontsize=14)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(scores)), scores.values, color='steelblue', alpha=0.8)\n",
    "plt.title('Mutual Information Feature Scores)', fontsize=14)\n",
    "plt.xlabel('Feature Index (original order)')\n",
    "plt.ylabel('Mutual Information')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest\n",
    "\n",
    "The graphs were created with the assistance of AI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=seed)\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(importances_sorted)), importances_sorted.values, color='steelblue', alpha=0.8)\n",
    "plt.title('Feature Importances', fontsize=14)\n",
    "plt.xlabel('Feature Index (sorted by importance)')\n",
    "plt.ylabel('Importance')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# correlation distribution\n",
    "plt.hist(importances.values, bins=50, color='orange', alpha=0.7)\n",
    "plt.title('Distribution of Feature Importances', fontsize=14)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(range(len(importances)), importances.values, color='steelblue', alpha=0.8)\n",
    "plt.title('Feature Importances', fontsize=14)\n",
    "plt.xlabel('Feature Index (original order)')\n",
    "plt.ylabel('Importance')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined selections\n",
    "\n",
    "The graphs were created with the assistance of AI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "titles = [\n",
    "    \"Absolute Correlation with Target\",\n",
    "    \"Mutual Information Scores\",\n",
    "    \"Random Forest Importances\"\n",
    "]\n",
    "data = [corr_abs, scores_sorted, importances_sorted]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.bar(range(len(data[i])), data[i].values, color='steelblue', alpha=0.8)\n",
    "    ax.set_title(titles[i], fontsize=13)\n",
    "    ax.set_xlabel(\"Feature Index (sorted)\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "combined_df = pd.DataFrame({\n",
    "    'Correlation': corr_abs.reindex(X.columns).fillna(0),\n",
    "    'MutualInformation': scores.reindex(X.columns).fillna(0),\n",
    "    'RandomForest': importances.reindex(X.columns).fillna(0)\n",
    "})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "combined_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(combined_df),\n",
    "    columns=combined_df.columns,\n",
    "    index=combined_df.index\n",
    ")\n",
    "\n",
    "combined_scaled[\"ConsensusScore\"] = combined_scaled.mean(axis=1)\n",
    "combined_scaled_sorted = combined_scaled.sort_values(\"ConsensusScore\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(\n",
    "    x=range(len(combined_scaled_sorted)),\n",
    "    y=combined_scaled_sorted[\"ConsensusScore\"].values,\n",
    "    color=\"steelblue\"\n",
    ")\n",
    "plt.title(\"Normalized Consensus Feature Importance (All Features)\", fontsize=14)\n",
    "plt.xlabel(\"Feature Index (sorted by consensus importance)\")\n",
    "plt.ylabel(\"Consensus Score (0–1)\")\n",
    "plt.xticks([])  # hide x labels\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(combined_scaled_sorted[\"ConsensusScore\"], bins=50, color='orange', alpha=0.7)\n",
    "plt.title(\"Distribution of Consensus Feature Importance\", fontsize=14)\n",
    "plt.xlabel(\"Consensus Score (0–1)\")\n",
    "plt.ylabel(\"Count of Features\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied a threshold to the combined feature selection to retain only the most relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "selected_features = combined_scaled_sorted[combined_scaled_sorted[\"ConsensusScore\"] >= threshold].index\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features out of {len(combined_scaled_sorted)}\")\n",
    "\n",
    "df_filtered = df[selected_features.tolist() + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1762287203109,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "cPX2qzKizRKg"
   },
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    def __init__(self, df_filtered):\n",
    "        X = df_filtered.iloc[:, :-1].values.astype(np.float32)\n",
    "        y = df_filtered.iloc[:, -1].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "        # Step 1: split off test set first\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Step 2: from the remaining 80%, make train/val split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
    "        )\n",
    "\n",
    "        print(y_train.mean(), y_val.mean(), y_test.mean())\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "\n",
    "        self.x_train = torch.tensor(X_train)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "        self.x_val = torch.tensor(X_val)\n",
    "        self.y_val = torch.tensor(y_val)\n",
    "        self.x_test = torch.tensor(X_test)\n",
    "        self.y_test = torch.tensor(y_test)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # class imbalance handling\n",
    "        pos = (y_train == 1).sum()\n",
    "        neg = (y_train == 0).sum()\n",
    "        self.pos_weight = torch.tensor([neg / max(pos, 1)], dtype=torch.float32).to(device)\n",
    "\n",
    "    def setup(self, cfg):\n",
    "        self.dataloader_train = torch.utils.data.dataloader.DataLoader(\n",
    "            torch.utils.data.TensorDataset(self.x_train, self.y_train), batch_size=cfg.batch_size,\n",
    "            shuffle=True, num_workers=cfg.num_workers, pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        self.dataloader_val = torch.utils.data.dataloader.DataLoader(\n",
    "            torch.utils.data.TensorDataset(self.x_val, self.y_val), batch_size=cfg.batch_size,\n",
    "            shuffle=False, num_workers=cfg.num_workers, pin_memory=torch.cuda.is_available()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1762287203137,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "3bhXgUH2zbYJ"
   },
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    def __init__(self):\n",
    "        self.values = dict()\n",
    "\n",
    "    def step(self, key, value):\n",
    "        sum, count = 1.0, 1.0\n",
    "        if key in self.values:\n",
    "            sum, count = self.values[key]\n",
    "        sum += value\n",
    "        count += 1\n",
    "        self.values[key] = sum, count\n",
    "\n",
    "    def get(self):\n",
    "        result = dict()\n",
    "        for k, (sum, count) in self.values.items():\n",
    "            result[k] = float(sum / count)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762287203145,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "MC6J6aswzdaI"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, hidden_sizes, p):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_features = n_in\n",
    "\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_features, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            if p > 0:\n",
    "                layers.append(nn.Dropout(p))\n",
    "            in_features = h\n",
    "\n",
    "        # final output layer: 1 logit\n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1762287203182,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "kFnYN82fzgOf"
   },
   "outputs": [],
   "source": [
    "class Trainer_Batch:\n",
    "    def __init__(self, cfg, model, loss, optimizer, epochs):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.cfg = cfg\n",
    "        self.history = {\"train\": [], \"val\": []}\n",
    "\n",
    "    def setup(self, datamodule):\n",
    "        self.datamodule = datamodule\n",
    "        self.datamodule.setup(self.cfg)\n",
    "\n",
    "    def train(self, patience=10):\n",
    "\n",
    "        # get all data at once\n",
    "        x_train, y_train = self.datamodule.x_train.to(self.device), self.datamodule.y_train.to(self.device)\n",
    "        x_val, y_val = self.datamodule.x_val.to(self.device), self.datamodule.y_val.to(self.device)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            stats = Statistics()\n",
    "\n",
    "            # training\n",
    "            self.model.train()\n",
    "            # with tqdm(self.datamodule.dataloader_train, desc=f\"Train: {epoch}\") as progress:\n",
    "            for x_train, y_train in self.datamodule.dataloader_val:#progress:\n",
    "                x_train = x_train.to(self.device)\n",
    "                y_train = y_train.to(self.device)\n",
    "\n",
    "                logits = self.model(x_train)\n",
    "                l = self.loss(logits, y_train)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                stats.step(\"loss_train\", l.item())\n",
    "                    # progress.set_postfix(stats.get())\n",
    "\n",
    "            # validating\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                # with tqdm(self.datamodule.dataloader_val, desc=f\"Val: {epoch}\") as progress:\n",
    "                for x_val, y_val in self.datamodule.dataloader_val:#progress:\n",
    "                    x_val = x_val.to(self.device)\n",
    "                    y_val = y_val.to(self.device)\n",
    "\n",
    "                    logits = self.model(x_val)\n",
    "                    l = self.loss(logits, y_val)\n",
    "\n",
    "                    stats.step(\"loss_val\", l.item())\n",
    "                        # progress.set_postfix(stats.get())\n",
    "\n",
    "            # store for plotting\n",
    "            self.history[\"train\"].append(stats.get()[\"loss_train\"])\n",
    "            self.history[\"val\"].append(stats.get()[\"loss_val\"])\n",
    "\n",
    "\n",
    "        # plt.figure(figsize=(8,5))\n",
    "        # plt.plot(self.history[\"train\"], label=\"Training Loss\")\n",
    "        # plt.plot(self.history[\"val\"], label=\"Validation Loss\")\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Loss\")\n",
    "        # plt.title(\"Training vs Validation Loss\")\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1762287299661,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "bRrB9LuKzLRe"
   },
   "outputs": [],
   "source": [
    "class Trainer_noBatch:\n",
    "    def __init__(self, cfg, model, loss, optimizer, epochs):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.cfg = cfg\n",
    "        self.history = {\"train\": [], \"val\": []}\n",
    "\n",
    "    def setup(self, datamodule):\n",
    "        self.datamodule = datamodule\n",
    "        self.datamodule.setup(self.cfg)\n",
    "\n",
    "    def train(self, patience=10):\n",
    "\n",
    "        # get all data at once\n",
    "        x_train, y_train = self.datamodule.x_train.to(self.device), self.datamodule.y_train.to(self.device)\n",
    "        x_val, y_val = self.datamodule.x_val.to(self.device), self.datamodule.y_val.to(self.device)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            stats = Statistics()\n",
    "\n",
    "            # training\n",
    "            self.model.train()\n",
    "            logits = self.model(x_train)\n",
    "            l = self.loss(logits, y_train)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            stats.step(\"loss_train\", l.item())\n",
    "\n",
    "            # validating\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(x_val)\n",
    "                l = self.loss(logits, y_val)\n",
    "\n",
    "                stats.step(\"loss_val\", l.item())\n",
    "\n",
    "            # store for plotting\n",
    "            self.history[\"train\"].append(stats.get()[\"loss_train\"])\n",
    "            self.history[\"val\"].append(stats.get()[\"loss_val\"])\n",
    "\n",
    "        # plt.figure(figsize=(8,5))\n",
    "        # plt.plot(self.history[\"train\"], label=\"Training Loss\")\n",
    "        # plt.plot(self.history[\"val\"], label=\"Validation Loss\")\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Loss\")\n",
    "        # plt.title(\"Training vs Validation Loss\")\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 744232,
     "status": "ok",
     "timestamp": 1762288372753,
     "user": {
      "displayName": "Branislav Bučko",
      "userId": "12660222924820457476"
     },
     "user_tz": -60
    },
    "id": "jKTLTiaVzpK8",
    "outputId": "4e43b6c0-4d5e-47cd-c8a9-bea234456eb8"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"tag\": {\"value\": \"test\"},\n",
    "        \"num_workers\": {\"value\": 0},\n",
    "        \"epochs\": {\n",
    "            \"values\": [20, 40, 60, 80]\n",
    "        },\n",
    "        \"lr\": {\n",
    "            \"values\": [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"values\": [0.0, 0.0001, 0.001]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0.0, 0.2, 0.5]\n",
    "        },\n",
    "        \"hidden_sizes\": {\n",
    "            \"values\": [\n",
    "                [128],\n",
    "                [256, 128],\n",
    "                [256, 128, 64],\n",
    "                [128, 128, 64]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"ZNEUS\")\n",
    "\n",
    "def train_sweep():\n",
    "    wandb.init()\n",
    "    cfg = wandb.config\n",
    "\n",
    "    datamodule = DataModule(df_filtered)\n",
    "\n",
    "    n_in = datamodule.x_train.shape[1]\n",
    "\n",
    "    model = MLP(n_in, hidden_sizes=cfg.hidden_sizes, p=cfg.dropout)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    trainer = Trainer_Batch(cfg, model,\n",
    "                       loss=torch.nn.BCEWithLogitsLoss(pos_weight=datamodule.pos_weight),\n",
    "                       optimizer=optimizer,\n",
    "                       epochs=cfg.epochs)\n",
    "    trainer.setup(datamodule)\n",
    "    trainer.train()\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(datamodule.x_test.to(device))\n",
    "        y_pred = torch.sigmoid(logits)\n",
    "        y_pred_labels = (y_pred > 0.5).float()\n",
    "\n",
    "        test_loss = trainer.loss(logits, datamodule.y_test.to(device))\n",
    "        acc = (y_pred_labels == datamodule.y_test.to(device)).float().mean()\n",
    "\n",
    "    # Log final metrics\n",
    "    wandb.log({\n",
    "        \"final_test_loss\": test_loss.item(),\n",
    "        \"final_test_acc\": acc.item()\n",
    "    })\n",
    "\n",
    "wandb.agent(sweep_id, function=train_sweep)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
